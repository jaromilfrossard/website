---
title: "Multiple Comparisons"
author: "Jaromil Frossard"
date: '2018-06-25'
categories: []
slug: multiple-comparisons
summary: A brief summary of multiple comparisons methods (in progress)
tags: []
bibliography: post.bib
draft: true
---



<div id="notation-in-progress" class="section level1">
<h1>Notation (in progress)</h1>
<p>The multiple comparisons framework assume <span class="math inline">\(m\)</span> tests which are split into the follwing table <span class="citation">(Benjamini and Hochberg 1995)</span>:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Significant test</th>
<th>Non-significant test</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>True <span class="math inline">\(H_0\)</span></td>
<td><span class="math inline">\(U\)</span></td>
<td><span class="math inline">\(V\)</span></td>
<td><span class="math inline">\(m_0\)</span></td>
</tr>
<tr class="even">
<td>FALSE <span class="math inline">\(H_0\)</span></td>
<td><span class="math inline">\(T\)</span></td>
<td><span class="math inline">\(S\)</span></td>
<td><span class="math inline">\(m-m_0 = m_1\)</span></td>
</tr>
<tr class="odd">
<td></td>
<td><span class="math inline">\(m - R\)</span></td>
<td><span class="math inline">\(R\)</span></td>
<td><span class="math inline">\(m\)</span></td>
</tr>
</tbody>
</table>
<p>In that setting, we assume:</p>
<ul>
<li><span class="math inline">\(m\)</span>: <strong>fix</strong> and <strong>known</strong></li>
<li><span class="math inline">\(m_0\)</span> and <span class="math inline">\(m_1\)</span>: <strong>fix</strong> but <strong>unknown</strong></li>
<li><span class="math inline">\(R\)</span> is an <strong>observed</strong> random variable</li>
<li><span class="math inline">\(U\)</span>, <span class="math inline">\(V\)</span>, <span class="math inline">\(T\)</span>, <span class="math inline">\(S\)</span> are <strong>unobserved</strong> random variable.</li>
<li><span class="math inline">\(V\)</span> is the number of <strong>type I error</strong> and <span class="math inline">\(S\)</span> is the total of <strong>type II error</strong>.</li>
<li><span class="math inline">\(E(U/m_0)=\alpha\)</span> if the tests are exacts, for a individual type I error probability <span class="math inline">\(\alpha\)</span>.</li>
</ul>
</div>
<div id="error-of-interest" class="section level1">
<h1>Error of interest</h1>
<p>Given the previous table, we define different type of error.</p>
<div id="family-wise-error-rate-fwer" class="section level5">
<h5>Family-wise error rate (FWER)</h5>
<p>Probability of making at leaste one type I error: <span class="math inline">\(FWER = Pr(V&gt;0) = q\)</span>.</p>
<p><strong>Variation</strong>:</p>
<ul>
<li>generalized FWER: <span class="math inline">\(u-FWER = Pr(V &gt; u)\)</span>.</li>
</ul>
<p><strong>False discovery rate (FDR)</strong>: Proportion of error amoung all significant tests: <span class="math inline">\(FDR = E(Q)\)</span> where <span class="math inline">\(Q = V/R\)</span> and <span class="math inline">\(FDR = 0\)</span> when <span class="math inline">\(R=0\)</span>.</p>
</div>
</div>
<div id="procedure-to-control-fwer." class="section level1">
<h1>Procedure to control FWER.</h1>
<p>Given the null hypothesis <span class="math inline">\(H_1, \dots, H_m\)</span> , with their corresponding <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_1, \dots, p_m\)</span>, we want to control at a level <span class="math inline">\(q\)</span> the FWER such that <span class="math inline">\(Pr(V &gt; 0) =Pr(\bigcup\limits_{i=1}^{m_0} p^0_{i}&lt;\alpha^\star) \leq q\)</span> where <span class="math inline">\(p^0_i\)</span> correspond to the <span class="math inline">\(m_0\)</span> hypothesis under the true null.</p>
<div id="bonferoni" class="section level2">
<h2><a href="https://en.wikipedia.org/wiki/Bonferroni_correction">Bonferoni</a></h2>
<p><strong>Procedure:</strong> Use <span class="math inline">\(\alpha^\star_i = q/m\)</span> for all <span class="math inline">\(i\)</span> as individual level.</p>
<p><strong>Proof</strong>: <span class="math display">\[FWER =  Pr\left( \bigcup\limits_{i=1}^{m_0} (p^0_{i}&lt;\alpha^\star )\right) \leq \sum_{i=1}^{m_0}Pr \left(p^0_i &lt; \alpha^\star \right) = m_0 \alpha^\star \leq  m \alpha^\star ~ \Rightarrow ~\alpha^\star =q/m \Leftrightarrow FWER \leq q \]</span></p>
</div>
<div id="holm" class="section level2">
<h2><a href="https://en.wikipedia.org/wiki/Holm-Bonferroni_method">Holm</a></h2>
<p><strong>Procedure:</strong> Sort the <span class="math inline">\(p\)</span>-values, <span class="math inline">\(p_{(1)}&lt; \dots&lt; p_{(m)}\)</span> with there corresponding hypothesis <span class="math inline">\(H_{(1)}, \dots&lt; H_{(m)}\)</span>. Reject all <span class="math inline">\(k\)</span> hypothesis <span class="math inline">\(H_{(1)}, \dots&lt; H_{(k)}\)</span>, such that <span class="math inline">\(p_{(k+1)} \geq \alpha^\star_{(k+1)} = q/(m - k)\)</span> and <span class="math inline">\(p_{(i)} \leq \alpha^\star_{(i)} = q/(m+1 -i)\)</span> for all <span class="math inline">\((i)\)</span> as individual level.</p>
<p><strong>Rationale:</strong> After sorting the <span class="math inline">\(p\)</span>-values, use the Bonferoni correction for the first hypothesis. If your reject <span class="math inline">\(H_{(1)}\)</span>: <strong>1.</strong> either we made a correct decision, <span class="math inline">\(H_{(1)}\)</span> is a false hypothesis (<span class="math inline">\(H_{(1)} \in H^1_1,\dots, H^1_{m_1}\)</span> and <span class="math inline">\(V=0\)</span>), and we can use the Bonferoni for the <span class="math inline">\(m-1\)</span> next hypothesis, <strong>2.</strong> either <span class="math inline">\(H_{(1)}\)</span> is a true hypothesis (<span class="math inline">\(H_{(1)} \in H^0_1,\dots, H^0_{m_0}\)</span> and <span class="math inline">\(V=1\)</span>), and our next decisions will not change the <span class="math inline">\(FWER=Pr(V&gt;0)\)</span> given <span class="math inline">\(V=1\)</span>.</p>
<p><strong>Proof:</strong> After <span class="math inline">\(k-1\)</span> correctely reject hypothesis, we need to proof that the <span class="math inline">\(k\)</span>th hypothesis is reject at a level <span class="math inline">\(q\leq FWER\)</span>, then:</p>
<p><span class="math display">\[FWER =  Pr\left(\bigcup\limits_{i=k}^{m_0} (p^0_{i}&lt;\alpha^\star_{(k)} )\right) \leq (m_0-k+1) \alpha^\star_{(k)} \leq (m-k+1) \alpha^\star_{(k)}  ~\Rightarrow ~ \alpha^\star_{(k)}  = q/(m-k+1) \Leftrightarrow FWER \leq q \]</span></p>
</div>
<div id="sidak-correction" class="section level2">
<h2><a href="https://en.wikipedia.org/wiki/%C5%A0id%C3%A1k_correction">Sidak correction</a></h2>
<p><strong>Procedure:</strong> Use the individual <span class="math inline">\(\alpha\)</span> level, <span class="math inline">\(\alpha_S = 1-(1-q)^{1/m}\)</span></p>
<p><strong>Rationale:</strong></p>
<p><strong>Proof:</strong></p>
<p><span class="math display">\[FWER =Pr(V&gt;0)= 1-Pr(V=0)=1-(1-\alpha_S)^m =q \Leftrightarrow \alpha_S = 1-(1-q)^{1/m}\]</span></p>
</div>
<div id="closure-principle" class="section level2">
<h2>Closure principle</h2>
<p><strong>Procedure:</strong> Reject <span class="math inline">\(H_i\)</span> at a <span class="math inline">\(q\)</span> level if all <span class="math inline">\(p\)</span>-value <span class="math inline">\(p^\ast_{1},\dots,p^\ast_P\)</span> corresponding to the hypothesis of all intersections <span class="math inline">\(H^\ast = \bigcap\limits_{i \in C} H_i\)</span> all <span class="math inline">\(P\)</span> subset <span class="math inline">\(C\)</span> of <span class="math inline">\(1,\dots,m\)</span> are reject at a <span class="math inline">\(q\)</span> level <span class="citation">(Hochberg and Tamhane 1987, <span class="citation">Bretz, Hothorn, and Westfall (2011)</span>)</span>.</p>
<p><strong>Rationale:</strong> With two hypothesis <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span> conditioning the decision on the closure <span class="math inline">\(H_{12}\)</span> implies a maximal FWER equal to the <span class="math inline">\(\alpha\)</span> level of the hypothesis <span class="math inline">\(H_{12}\)</span>.</p>
<p><strong>Proof:</strong></p>
<p>We call the decision about our hypothesis under closure <span class="math inline">\(A = \textrm{reject at leat one } H_i ~| \textrm{ reject } H^\ast\)</span> and the event of the closure <span class="math inline">\(B = \textrm{reject } H^\ast\)</span>. Then we know that <span class="math inline">\(A=A\cap B\)</span> and we derive:</p>
<p><span class="math display">\[Pr(A) = Pr(A\cap B)  = Pr (B)Pr(A|B)&lt; q\]</span></p>
</div>
</div>
<div id="resampling-method-to-control-the-fwer" class="section level1">
<h1>Resampling method to control the FWER</h1>
<p>Given <span class="math inline">\(m\)</span> hypothesis <span class="math inline">\(H_{1}, \dots, H_{m}\)</span>, we compute <span class="math inline">\(m\)</span> statistics <span class="math inline">\(T_{1}, \dots, T_{m}\)</span>. Resampling technics allows us to compute <span class="math inline">\(m\)</span> resampling distribution <span class="math inline">\(T_{1}^\star, \dots, T_{m}^\star\)</span> of length <span class="math inline">\(B\)</span>. The <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_{1}, \dots p_{m}\)</span> are computed using <span class="math inline">\(p_j =\# (T^\star_j \geq T_j)/B\)</span>. Moreover for each element of the <span class="math inline">\(T^\star_j\)</span>, we use the previous formula to compute the resampling distributions of <span class="math inline">\(p\)</span>-value, <span class="math inline">\(p_{1}^\star, \dots p_{m}^\star\)</span>. Using the correct resampling technics, we interpret the matrices <span class="math inline">\(T^\star =[T_{1}^\star~ \dots ~ T_{m}^\star]\)</span> and <span class="math inline">\(p^\star=[p_{1}^\star~\dots ~ p_{m}^\star]\)</span> as multivariate resampling distributions with variable in columns and re-sample in rows.</p>
<div id="maxtminp" class="section level2">
<h2>maxT/minP</h2>
<p><strong>Procedure:</strong> By taking the maximum value for each row of <span class="math inline">\(T^\star\)</span> (or the minium of each row of <span class="math inline">\(p^\star\)</span>), we compute the resampling distribution of the extremum <span class="math inline">\(E^\star\)</span>. Each <span class="math inline">\(T_{1}, \dots, T_{m}\)</span> (<span class="math inline">\(p_{1}, \dots, p_{m}\)</span>) is then compared to the distribution <span class="math inline">\(E^\star\)</span> to computed the corrected <span class="math inline">\(p\)</span>-values <span class="citation">(Westfall and Young 1993)</span></p>
<p><strong>Rationale:</strong> The distribution of the extremum <span class="math inline">\(E^\star\)</span> is computed.</p>
<p><strong>Proof:</strong></p>
</div>
<div id="troendle-stepwise-maxtminp" class="section level2">
<h2>Troendle (stepwise maxT/minP)</h2>
<p><strong>Procedure:</strong> Sort the statistics such that <span class="math inline">\(T_{(1)}&gt; \dots&gt; T_{(m)}\)</span> which correspond to the hypothesis <span class="math inline">\(H_{(1)}, \dots, H_{(m)}\)</span>. The multivariate distribution is then <span class="math inline">\(T^{(\star)} = [ T_{(1)}^\star ~ \dots ~ T_{(m)}^\star]\)</span>. The corrected <span class="math inline">\(p\)</span>-values <span class="math inline">\(p_{(1)}^{corr},\dots,p_{(m)}^{corr}\)</span> are computed for each statistics <span class="math inline">\(T_{(j)}\)</span> is compared to the distribution <span class="math inline">\(E^\star_{j}\)</span> maximum over the row of the matrix <span class="math inline">\([ T_{(j)}^\star ~ \dots ~ T_{(m)}^\star]\)</span>. Reject all hypothesis <span class="math inline">\(H_{(1)}, \dots, H_{(j)}\)</span> such that <span class="math inline">\(p_{(j+1)}^{corr}&gt;q\)</span>.</p>
<p><strong>Rationale:</strong> Using the same argument as Holm, by sorting the statistics, at each step, we compute a maxT/minP correction for all remaining test and stop the procedure when one test is not significant.</p>
</div>
</div>
<div id="procedure-to-control-the-fdr" class="section level1">
<h1>Procedure to control the (FDR)</h1>
<div id="benjamini-hochberg-bh" class="section level2">
<h2><a href="https://en.wikipedia.org/wiki/False_discovery_rate">Benjamini-Hochberg (BH)</a></h2>
<p><strong>Procedure:</strong> Sort the <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_{(1)}&lt;\dots &lt;p_{(m)}\)</span>, and the hypothesis <span class="math inline">\(H_{(1)}&lt;\dots &lt;H_{(m)}\)</span> and reject all <span class="math inline">\(k\)</span> hypothesis such that <span class="math inline">\(p_{(k)}\)</span> is the <span class="math inline">\(p\)</span>-value such that <span class="math inline">\(p_{(k)}&lt;k/m \alpha\)</span>. <span class="citation">(Benjamini and Hochberg 1995)</span></p>
<p><strong>Rationale:</strong></p>
<p><strong>Proof:</strong></p>
</div>
</div>
<div id="bibliography" class="section level1 unnumbered">
<h1>Bibliography</h1>
<div id="refs" class="references">
<div id="ref-benjamini_controlling_1995">
<p>Benjamini, Yoav, and Yosef Hochberg. 1995. “Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, 289–300.</p>
</div>
<div id="ref-bretz_multiple_2011">
<p>Bretz, Frank, Torsten Hothorn, and Peter H. Westfall. 2011. <em>Multiple Comparisons Using R</em>. Boca Raton, FL: CRC Press.</p>
</div>
<div id="ref-hochberg_multiple_1987">
<p>Hochberg, Yosef, and Ajit C. Tamhane. 1987. <em>Multiple Comparison Procedures</em>. Wiley.</p>
</div>
<div id="ref-westfall_resampling-based_1993">
<p>Westfall, Peter H., and S. Stanley Young. 1993. <em>Resampling-Based Multiple Testing: Examples and Methods for P-Value Adjustment</em>. 1 edition. New York: Wiley-Interscience.</p>
</div>
</div>
</div>
