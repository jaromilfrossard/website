---
title: "Multiple Comparisons"
author: "Jaromil Frossard"
date: '2018-06-25'
categories: []
slug: multiple-comparisons
summary: A brief summary of multiple comparisons methods (in progress)
tags: []
bibliography: post.bib
---

# Notation (in progress)

The multiple comparisons framework assume $m$ tests which are split into the follwing table [@benjamini_controlling_1995]:


| | Significant test | Non-significant test | |
| --- | --- | --- | --- |
| True $H_0$   | $U$ | $V$ | $m_0$ |
| FALSE $H_0$ | $T$ | $S$ | $m-m_0 = m_1$ |
| | $m - R$ | $R$ | $m$ |


In that setting, we assume: 

* $m$: **fix** and **known**
* $m_0$ and $m_1$: **fix** but **unknown**
* $R$ is an **observed** random variable
* $U$, $V$, $T$, $S$ are **unobserved** random variable.
* $V$ is the number of **type I error** and $S$ is the total of **type II error**. 
* $E(U/m_0)=\alpha$ if the tests are exacts, for a individual type I error probability $\alpha$.  

# Error of interest

Given the previous table, we define different type of error.

##### Family-wise error rate (FWER)

Probability of making at leaste one type I error: $FWER = Pr(V>0) = q$.

__Variation__: 

* generalized FWER: $u-FWER = Pr(V > u)$.

__False discovery rate (FDR)__: Proportion of error amoung all significant tests: $FDR = E(Q)$ where $Q = V/R$ and $FDR = 0$ when $R=0$.

# Procedure to control FWER.

Given the null hypothesis $H_1, \dots, H_m$ , with their corresponding $p$-value $p_1, \dots, p_m$, we want to control at a level $q$ the FWER such that $Pr(V > 0) =Pr(\bigcup\limits_{i=1}^{m_0} p^0_{i}<\alpha^\star) \leq q$ where $p^0_i$ correspond to the $m_0$ hypothesis under the true null.

## [Bonferoni](https://en.wikipedia.org/wiki/Bonferroni_correction) 

__Procedure:__
Use $\alpha^\star_i = q/m$ for all $i$ as individual level.

__Proof__:
$$FWER =  Pr\left( \bigcup\limits_{i=1}^{m_0} (p^0_{i}<\alpha^\star )\right) \leq \sum_{i=1}^{m_0}Pr \left(p^0_i < \alpha^\star \right) = m_0 \alpha^\star \leq  m \alpha^\star ~ \Rightarrow ~\alpha^\star =q/m \Leftrightarrow FWER \leq q $$



## [Holm](https://en.wikipedia.org/wiki/Holm-Bonferroni_method)

__Procedure:__ 
Sort the $p$-values, $p_{(1)}< \dots< p_{(m)}$ with there corresponding hypothesis $H_{(1)}, \dots< H_{(m)}$. Reject all $k$ hypothesis $H_{(1)}, \dots< H_{(k)}$, such that $p_{(k+1)} \geq \alpha^\star_{(k+1)} = q/(m - k)$ and $p_{(i)} \leq \alpha^\star_{(i)} = q/(m+1 -i)$ for all $(i)$ as individual level.

__Rationale:__
After sorting the $p$-values, use the Bonferoni correction for the first hypothesis. If your reject $H_{(1)}$: __1.__ either we made a correct decision, $H_{(1)}$ is a false hypothesis ($H_{(1)} \in H^1_1,\dots, H^1_{m_1}$ and $V=0$), and we can use the Bonferoni for the $m-1$ next hypothesis, __2.__ either $H_{(1)}$ is a true hypothesis ($H_{(1)} \in H^0_1,\dots, H^0_{m_0}$ and $V=1$), and our next decisions will not change the $FWER=Pr(V>0)$ given $V=1$.

__Proof:__
After $k-1$ correctely reject hypothesis, we need to proof that the $k$th hypothesis is reject at a level $q\leq FWER$, then:

$$FWER =  Pr\left(\bigcup\limits_{i=k}^{m_0} (p^0_{i}<\alpha^\star_{(k)} )\right) \leq (m_0-k+1) \alpha^\star_{(k)} \leq (m-k+1) \alpha^\star_{(k)}  ~\Rightarrow ~ \alpha^\star_{(k)}  = q/(m-k+1) \Leftrightarrow FWER \leq q $$

## [Sidak correction](https://en.wikipedia.org/wiki/%C5%A0id%C3%A1k_correction)

__Procedure:__ 
Use the individual $\alpha$ level, $\alpha_S = 1-(1-q)^{1/m}$

__Rationale:__


__Proof:__

$$FWER =Pr(V>0)= 1-Pr(V=0)=1-(1-\alpha_S)^m =q \Leftrightarrow \alpha_S = 1-(1-q)^{1/m}$$


## Closure principle

__Procedure:__ 
Reject $H_i$ at a $q$ level if all $p$-value $p^\ast_{1},\dots,p^\ast_P$ corresponding to the hypothesis of all intersections $H^\ast = \bigcap\limits_{i \in C} H_i$ all $P$ subset $C$ of $1,\dots,m$ are reject at a $q$ level [@hochberg_multiple_1987, @bretz_multiple_2011].

__Rationale:__
With two hypothesis $H_1$ and $H_2$ conditioning the decision on the closure $H_{12}$ implies a maximal FWER equal to the $\alpha$ level of the hypothesis $H_{12}$.  

__Proof:__

We call the decision about our hypothesis under closure $A = \textrm{reject at leat one } H_i ~| \textrm{ reject } H^\ast$ and the event of the closure  $B = \textrm{reject } H^\ast$. Then we know that $A=A\cap B$ and we derive:

$$Pr(A) = Pr(A\cap B)  = Pr (B)Pr(A|B)< q$$

# Resampling method to control the FWER

Given $m$ hypothesis $H_{1}, \dots, H_{m}$, we compute $m$ statistics $T_{1}, \dots, T_{m}$. Resampling technics allows us to compute $m$ resampling distribution $T_{1}^\star, \dots, T_{m}^\star$ of length $B$. The $p$-value $p_{1}, \dots p_{m}$ are computed using $p_j =\# (T^\star_j \geq T_j)/B$. Moreover for each element of the $T^\star_j$, we use the previous formula to compute the resampling distributions of $p$-value, $p_{1}^\star, \dots p_{m}^\star$. Using the correct resampling technics, we interpret the matrices $T^\star =[T_{1}^\star~ \dots ~ T_{m}^\star]$ and $p^\star=[p_{1}^\star~\dots ~ p_{m}^\star]$ as multivariate resampling distributions with variable in columns and re-sample in rows.


## maxT/minP

__Procedure:__
By taking the maximum value for each row of $T^\star$ (or the minium of each row of $p^\star$), we compute the resampling distribution of the extremum $E^\star$. Each $T_{1}, \dots, T_{m}$ ($p_{1}, \dots, p_{m}$) is then compared to the distribution $E^\star$ to computed the corrected $p$-values [@westfall_resampling-based_1993]

__Rationale:__
The distribution of the extremum $E^\star$ is computed.

__Proof:__


## Troendle (stepwise maxT/minP)

__Procedure:__
Sort the statistics such that $T_{(1)}> \dots> T_{(m)}$ which correspond to the hypothesis $H_{(1)}, \dots, H_{(m)}$. The multivariate distribution is then  $T^{(\star)} = [ T_{(1)}^\star ~ \dots ~ T_{(m)}^\star]$. The corrected $p$-values $p_{(1)}^{corr},\dots,p_{(m)}^{corr}$ are computed for each statistics $T_{(j)}$ is compared to the distribution $E^\star_{j}$ maximum over the row of the matrix $[ T_{(j)}^\star ~ \dots ~ T_{(m)}^\star]$. Reject all hypothesis $H_{(1)}, \dots, H_{(j)}$ such that $p_{(j+1)}^{corr}>q$ [@troendle_stepwise_1995].

__Rationale:__
Using the same argument as Holm, by sorting the statistics, at each step, we compute a maxT/minP correction for all remaining test and stop the procedure when one test is not significant.


# Procedure to control the (FDR)

## [Benjamini-Hochberg (BH)](https://en.wikipedia.org/wiki/False_discovery_rate)


__Procedure:__
Sort the $p$-value $p_{(1)}<\dots <p_{(m)}$, and the hypothesis $H_{(1)}<\dots <H_{(m)}$ and reject all $k$ hypothesis such that $p_{(k)}$ is the $p$-value such that $p_{(k)}<k/m \alpha$. [@benjamini_controlling_1995]

__Rationale:__

__Proof:__


# Bibliography
