---
title: Graphical Representation of the Cluster-Mass Test using rayrender
author: Jaromil Frossard
date: '2019-11-11'
slug: []
categories:
  - R
tags:
  - Cluster-mass
  - EEG
  - ERP
  - FWER
  - R
  - rayrender
subtitle: ''
summary: 'A tutorial to R to produce 3D video of EEG cluster-mass test using rayrender'
authors: []
lastmod: '2019-11-10T19:44:50+02:00'
draft: false
featured: yes
image:
  caption: ''
  focal_point: ''
  preview_only: yes
projects: []
bibliography: post.bib
url_code: "script/2019_11_11_headset-rayrender.R"
---



<p>Using the R package <a href="http://www.rayrender.net/">rayrender</a>, it is really easy to quickly produce 3D images and videos. Here you will learn how to produce a visualization of a full-scalp cluster-mass test of EEG data using <a href="http://www.rayrender.net/">rayrender</a>. The EEG data comes from <span class="citation">Cheval et al. (2018)</span>. You can already repoduce the analysis using the <a href="https://github.com/jaromilfrossard/clustergraph">clustergraph</a> and following a <a href="https://jaromilfrossard.netlify.com/post/2018-08-06-full-scalp-cluster-mass-test-for-eeg/">previous post</a>. The <a href="https://github.com/jaromilfrossard/clustergraph">clustergraph</a> package is an extension of permuco <span class="citation">Frossard and Renaud (2018)</span>. It has a build-in image() function that produce visualistion of the results of the test as a heatmap. Here, we propose to visualize this effect by creating a short video.</p>
<p>Before following the next steps of this tutorial make sure you have:</p>
<ol style="list-style-type: decimal">
<li>Installed the <a href="http://www.rayrender.net/">rayrender</a> package and read the introduction tutorial.</li>
<li>Installed the <a href="https://github.com/jaromilfrossard/clustergraph">clustergraph</a> package. Run the script in my <a href="https://jaromilfrossard.netlify.com/post/2018-08-06-full-scalp-cluster-mass-test-for-eeg/">previous post</a> in order to:
<ul>
<li><ol style="list-style-type: decimal">
<li>Download the electrode position data from &lt;www.biosemi.com&gt; and save it as “Cap_coords_all.xls”</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Save the “model” object (the output of the clustergraph() function) in file named “model.RData”</li>
</ol></li>
</ul></li>
<li>Downloaded a 3D model of a female-head: <a href="https://free3d.com/3d-model/femalehead-v4--971578.html" class="uri">https://free3d.com/3d-model/femalehead-v4--971578.html</a>.</li>
</ol>
<div id="r-tutorial" class="section level2">
<h2>R Tutorial</h2>
<p>First load the packages, and the clustergraph() model:</p>
<pre class="r"><code>library(tidyr)
library(dplyr)
library(rayrender)
library(xlsx)
library(permuco)
# devtools::install_github(&quot;jaromilfrossard/clustergraph&quot;)
library(clustergraph)

## Import data from the clustergraph() object
load(&quot;model.RData&quot;)</code></pre>
<p>We will make a 3D visuallisation of the following effect of interaction:</p>
<pre class="r"><code>effect &lt;- 6
image(model, effect = effect)</code></pre>
<p><img src="/img/heatmap.png" /></p>
<p>We will need data by time-point and by channel of the results of the cluster-mass test for this particular effect. It can be found in the model object. We also have to rename a column in for the next steps of the data manipulation:</p>
<pre class="r"><code>df &lt;- (model$multiple_comparison[[effect]]$maris_oostenveld$data)%&gt;%
  rename(channel = &quot;electrode&quot;)%&gt;%
  mutate(channel = as.character(channel))</code></pre>
<p>Then, we load data of the 3D position of the electrodes from &lt;www.biosemi.com&gt;. We make sure to center and rescale the position of the electrodes as it will be easier to construct and visualize the 3D model of the headset:</p>
<pre class="r"><code>## Import the position of electrods
# download.file(&quot;https://www.biosemi.com/download/Cap_coords_all.xls&quot;,&quot;Cap_coords_all.xls&quot;,mode=&quot;wb&quot;)
df_head &lt;-  read.xlsx(file=&quot;Cap_coords_all.xls&quot;, sheetIndex = 3, header =T,startRow=34)
df_head &lt;- df_head[1:64,c(1,5:7)]
colnames(df_head) &lt;- c(&quot;channel&quot;,&quot;x&quot;,&quot;y&quot;,&quot;z&quot;)

## Rename channel, center position and do a first rescale of the electrodes
ratio &lt;- 100
df_head &lt;- df_head%&gt;%
  mutate(channel = plyr::revalue(channel, 
                   c(&quot;T7 (T3)&quot; = &quot;T7&quot;, &quot;Iz (inion)&quot; = &quot;Iz&quot;, &quot;T8 (T4)&quot; = &quot;T8&quot;, &quot;Afz&quot; = &quot;AFz&quot;)))%&gt;%
  mutate(channel = as.character(channel))%&gt;%
  mutate(z = (z-mean(z))/ratio,
         x = (x-mean(x))/ratio,
         y=(y-mean(y))/ratio)</code></pre>
<p>Then join data from the postion of the headset and from the cluster-mass test</p>
<pre class="r"><code>## Join the to data frames
df &lt;- df%&gt;%
  inner_join(df_head, by=&quot;channel&quot;)</code></pre>
<p>Now we will create the 3D model. First we include the 3D face in a empty scene. The face will be in a non-reflective material as we use the lambertian() function in a greenish color. Other parameters allow to rotate, translate and rescale the 3D model.</p>
<pre class="r"><code>## Download the Female Head from free3d.com
## Unzip the folder named FemaleHead
## Save the path of the .obj file
head_obj &lt;- &quot;FemaleHead/11091_FemaleHead_v4.obj&quot;

## Define the color of the face
face_col &lt;- rgb(50,25,00, maxColorValue = 255)

## Add the face in a scene
scene_head &lt;- NULL
scene_head &lt;- scene_head%&gt;%
  add_object(obj_model(head_obj, 
                       y= -.8, scale_obj =.15,angle =c(90,180,0),
                       material = lambertian(color=face_col,noise=.02)))</code></pre>
<p>Now we construct the headset by assembling several sphere. We will display the tests of 40 time-points (78 ms). Electrodes in metalic red are inside a significant cluster, in metalic grey are inside a non-significant cluster and the transparent one are not part of a cluster. Using <a href="http://www.rayrender.net/">rayrender</a>, we construct all electrode in the appropriate position, using a for loop and we the function group_objects() we group the 64 electrodes in a unique object that we can manipulate. By try and error, we found the best translation, rotation and rescale of the headset.</p>
<pre class="r"><code>## Define colors of the electodes
red_col &lt;- rgb(255,0,0,maxColorValue = 255)
grey_col &lt;- rgb(128,128,128,maxColorValue = 255)

## Select a particular time
ti &lt;- 40
df_ti &lt;- filter(df,time==ti)

## Create a 3D headset at time ti
eeg_object  &lt;- NULL

for(channeli in 1:nrow(df_ti)){
  if((df_ti$cluster_id[channeli])==0){
    ## transparent electrod without outside clusters
    materiali &lt;- dielectric(color = grey_col)
  }else if((df_ti$pvalue[channeli])&lt;0.05){
    ## Red electrodes for significative cluster
    materiali &lt;- metal(color = red_col)
  }else if((df_ti$pvalue[channeli])&gt;0.05){
    ## Grey electrodes for non-significative cluster
    materiali &lt;- metal(color = grey_col)
  }
    
  ## add the new electrodes
  eeg_object &lt;- 
    eeg_object%&gt;%
    add_object(sphere(x = df_ti$x[channeli], y = df_ti$y[channeli],
                      z = df_ti$z[channeli], radius = .05,
                      material = materiali))
}

## Group the electrode into a headset, finale rescale of the electrode.
headset &lt;- group_objects(eeg_object,group_translate = c(0,1.45,.2),
                            group_angle = c(90,0,0),group_scale = 1.15*c(.92,1,1))</code></pre>
<p>Next we add the headset to the scene containing the head only.</p>
<pre class="r"><code>## Add the headset on the scene/head
scene &lt;- 
  scene_head%&gt;%
  add_object(headset)</code></pre>
<p>Finally we plot 4 differents points of view in order to have preview of the effect. The computation may take a long time so you try lower quality setting first.</p>
<pre class="r"><code>## select the point of view
lookfrom_list = list(c(3,5,7),
                     c(3,5,-7),
                     c(-3,5,7),
                     c(-3,5,-7))

lookat_list = list(c(0,.75,0),
                   c(0,.8,0),
                   c(0,.75,0),
                   c(0,.8,0))

## select the quality of the scene
sample = 2000 # 20 
width = height = 400 # 200

par(mfrow=c(2,2),oma=c(0,0,5,0),mar=c(0,0,0,0))
for(i in 1:4){
  render_scene(scene, parallel=TRUE,lookfrom=lookfrom_list[[i]],
               lookat = lookat_list[[i]],ambient_light =T,
               sample=sample,width = width ,height=height)
}
title_txt = paste0(names(model$multiple_comparison)[[effect]],&quot;, time: &quot;,round(ti/512*1000),&quot; [ms]&quot;)
title(main = title_txt,outer=T,cex.main = 2)</code></pre>
<p><img src="/img/headset.png" /></p>
<p>Now we can simply put the last part of the script in a for loop in create 1 image per time points. We we save them in the img folders:</p>
<pre class="r"><code>for (ti in 1:max(df$time)){
  df_ti &lt;- filter(df,time==ti)
  
  eeg_object  &lt;- NULL
  for(channeli in 1:nrow(df_ti)){
    if((df_ti$cluster_id[channeli])==0){
      materiali &lt;- dielectric(color = grey_col)
      }else if((df_ti$pvalue[channeli])&lt;0.05){
        materiali &lt;- metal(color = red_col)
        }else if((df_ti$pvalue[channeli])&gt;0.05){
          materiali &lt;- metal(color = grey_col)
          }
    ## add the new electrodes
    eeg_object &lt;- 
      eeg_object%&gt;%
      add_object(sphere(x = df_ti$x[channeli], y = df_ti$y[channeli],
                        z = df_ti$z[channeli], radius = .05,
                        material = materiali))
    }
  ## Group the electrode into a headset, finale rescale of the electrode.
  head_set &lt;- group_objects(eeg_object,group_translate = c(0,1.45,.2),
                            group_angle = c(90,0,0),group_scale = 1.15*c(.92,1,1))

  ## Add the electrode on the scene/head
  scene &lt;-
    scene_head%&gt;%
    add_object(head_set)

  ## select the quality of the scene
  sample = 2000 #20
  width = height = 400 #200
  
  png(filename = paste0(&quot;img/img&quot;,sprintf(&quot;%04d&quot;,ti),&quot;.png&quot;), width = 800, height = 800)
  par(mfrow=c(2,2),oma=c(0,0,5,0),mar=c(0,0,0,0))
  for(i in 1:4){
    render_scene(scene, parallel=TRUE,lookfrom=lookfrom_list[[i]],
                 lookat = lookat_list[[i]],ambient_light =T,
                 sample=sample,width = width ,height=height)
  }
  title_txt = paste0(names(model$multiple_comparison)[[effect]],&quot;, time: &quot;,
                     round(ti/512*1000),&quot; [ms]&quot;)
  title(main = title_txt,outer=T,cex.main = 2)
  dev.off()}</code></pre>
<p>Finally, we create a video using the following script in R:</p>
<pre class="r"><code>system(&quot;ffmpeg -framerate 30 -pix_fmt yuv420p -i img/img%04d.png headset.mp4&quot;)</code></pre>
</div>
<div id="bibliography" class="section level1 unnumbered">
<h1>Bibliography</h1>
<div id="refs" class="references">
<div id="ref-cheval_avoiding_2018">
<p>Cheval, Boris, Eda Tipura, Nicolas Burra, Jaromil Frossard, Julien Chanal, Dan Orsholits, Remi Radel, and Matthieu P. Boisgontier. 2018. “Avoiding Sedentary Behaviors Requires More Cortical Resources Than Avoiding Physical Activity: An EEG Study.” <em>Neuropsychologia</em> 119: 68–80. <a href="https://doi.org/10.1016/j.neuropsychologia">https://doi.org/10.1016/j.neuropsychologia</a>.</p>
</div>
<div id="ref-frossard_permuco_2018">
<p>Frossard, Jaromil, and Olivier Renaud. 2018. “Permuco: Permutation Tests for Regression, (Repeated Measures) ANOVA/ANCOVA and Comparison of Signals.”</p>
</div>
</div>
</div>
